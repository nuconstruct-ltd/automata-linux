#!/bin/bash

# ============================================================================
# Path Detection - Support both installed and development modes
# ============================================================================
SCRIPT_PATH="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Check if installed via package manager (highest priority)
if [ -d "/usr/local/share/atakit/scripts" ]; then
    INSTALL_DIR="/usr/local/share/atakit"
    SCRIPT_DIR="$INSTALL_DIR/scripts"
    WORKLOAD_DIR="$INSTALL_DIR/workload"
    TOOLS_DIR="$INSTALL_DIR/tools"
    IS_INSTALLED=true
elif [ -d "/usr/share/atakit/scripts" ]; then
    # Alternative system installation path
    INSTALL_DIR="/usr/share/atakit"
    SCRIPT_DIR="$INSTALL_DIR/scripts"
    WORKLOAD_DIR="$INSTALL_DIR/workload"
    TOOLS_DIR="$INSTALL_DIR/tools"
    IS_INSTALLED=true
elif [ -d "/opt/homebrew/share/atakit/scripts" ]; then
    # Homebrew on Apple Silicon
    INSTALL_DIR="/opt/homebrew/share/atakit"
    SCRIPT_DIR="$INSTALL_DIR/scripts"
    WORKLOAD_DIR="$INSTALL_DIR/workload"
    TOOLS_DIR="$INSTALL_DIR/tools"
    IS_INSTALLED=true
elif [ -d "$SCRIPT_PATH/scripts" ]; then
    # Running from git clone (development mode)
    SCRIPT_DIR="$SCRIPT_PATH/scripts"
    WORKLOAD_DIR="$SCRIPT_PATH/workload"
    TOOLS_DIR="$SCRIPT_PATH/tools"
    IS_INSTALLED=false
else
    echo "‚ùå Error: Cannot locate atakit installation"
    exit 1
fi

# Create working directory for artifacts and disk images
# When installed: use ~/.atakit for user data
# When in dev mode: use ./_artifacts in repo
if [ "$IS_INSTALLED" = true ]; then
    CVM_HOME="$HOME/.atakit"
    ARTIFACT_DIR="$CVM_HOME/artifacts"
    DISK_DIR="$CVM_HOME/disks"
    mkdir -p "$ARTIFACT_DIR" "$DISK_DIR"
else
    ARTIFACT_DIR="$SCRIPT_PATH/_artifacts"
    DISK_DIR="$SCRIPT_PATH"
    mkdir -p "$ARTIFACT_DIR"
fi

# Export variables so child scripts can inherit them
export ARTIFACT_DIR
export SCRIPT_DIR
export TOOLS_DIR
export WORKLOAD_DIR

# ============================================================================
# Dependency Checking and Auto-Installation
# ============================================================================
check_and_install_dependencies() {
    local missing=()
    local deps=("curl" "jq" "unzip" "openssl")

    for dep in "${deps[@]}"; do
        if ! command -v "$dep" &> /dev/null; then
            missing+=("$dep")
        fi
    done

    # Check for sha256sum or shasum (macOS uses shasum)
    if ! command -v sha256sum &> /dev/null && ! command -v shasum &> /dev/null; then
        missing+=("coreutils")  # provides sha256sum
    fi

    if [[ ${#missing[@]} -gt 0 ]]; then
        echo "‚ö†Ô∏è  Missing dependencies: ${missing[*]}"
        echo "‚åõ Attempting to install..."

        if [[ "$(uname)" == "Darwin" ]]; then
            # macOS - use Homebrew
            if command -v brew &> /dev/null; then
                brew install "${missing[@]}" || {
                    echo "‚ùå Failed to install dependencies via Homebrew"
                    exit 1
                }
            else
                echo "‚ùå Homebrew not found. Please install dependencies manually:"
                echo "  brew install ${missing[*]}"
                exit 1
            fi
        elif command -v apt-get &> /dev/null; then
            # Debian/Ubuntu
            sudo apt-get update -qq && sudo apt-get install -y "${missing[@]}" || {
                echo "‚ùå Failed to install dependencies via apt-get"
                exit 1
            }
        else
            echo "‚ùå Could not detect package manager. Please install manually:"
            echo "  ${missing[*]}"
            exit 1
        fi

        echo "‚úÖ Dependencies installed successfully"
    fi
}

# Run dependency check early
check_and_install_dependencies

usage() {
    echo "Usage: $0 <command> [options]"
    echo ""
    echo "Commands:"
    echo "  deploy-azure             Deploy a VM onto Azure using azure_disk.vhd."
    echo "  deploy-aws               Deploy a VM onto AWS using aws_disk.vmdk."
    echo "  deploy-gcp               Deploy a VM onto GCP using gcp_disk.tar.gz."
    echo "  update-workload          Update the workload on a deployed CVM."
    echo "  get-disk                 Get the disk image for a specific Cloud Provider."
    echo "  download-build-provenance  Download SLSA build provenance from GitHub Release."
    echo "  verify-build-provenance    Verify SLSA build provenance for a disk image."
    echo "  update-disk              Update the workload on a specified disk file."
    echo "  get-logs                 Retrieve logs from a deployed CVM."
    echo "  cleanup                  Clean up resources for a specific Cloud Provider and VM Name."
    echo "  cleanup-local            Remove all locally downloaded disk images, build provenance, and artifacts."
    echo "  sign-image               Sign and verify a container image using Cosign."
    echo "  generate-livepatch-keys  Generate livepatch keys to use with the CVM."
    echo "  sign-livepatch           Sign a livepatch file."
    echo "  livepatch                Deploy a kernel livepatch to a deployed CVM."
    echo "  maintenance              Enable or disable maintenance mode (SSH access) on a deployed CVM."
    echo ""
    echo "Optional arguments for 'deploy-azure' command:"
    echo "  --resource_group <group>    The resource group for the deployment. Default: randomly generated"
    echo "  --storage_account <name>    The name of a custom storage account. Default: randomly generated"
    echo "  --gallery_name <name>       The name of a shared image gallery. Default: randomly generated"
    echo "  --vm_name <name>            The name of the virtual machine. Default: cvm-test"
    echo "  --additional_ports <ports>  Comma-separated list of additional ports to open (e.g., \"80,443\"). Default: None"
    echo "  --vm_type <type>            The type of VM to be deployed. Default: \"Standard_DC2es_v6\""
    echo "  --region <region>           The region where the VM will be deployed. Default: \"East US\""
    echo "  --add-workload [path]       Update the workload on the disk before deploying. Default: ./workload"
    echo "  --attach-disk               The data disk name, if the disk with the provided name is not provided, it will be created by the script"
    echo "  --disk-size                 The data disk size. Default: 10 GB"
    echo "  --create-ip <name>          Auto-create a static IP with this name (idempotent). Default: None"

    echo ""
    echo "Optional arguments for 'deploy-gcp' command:"
    echo "  --project_id <id>           The project id for the deployment. Default: the default gcloud project"
    echo "  --bucket <name>             The name of a gcp bucket to store the vm image to. Default: randomly generated"
    echo "  --additional_ports <ports>  Comma-separated list of additional ports to open (e.g., \"80,443\"). Default: None"
    echo "  --vm_name <name>            The name of the virtual machine. Default: cvm-test"
    echo "  --region <region>           The region where the VM will be deployed. Default: \"asia-southeast1-b\""
    echo "  --vm_type <type>            The type of VM to be deployed. Default: \"c3-standard-4\""
    echo "  --ip <ip>                   Static ip to attach to the VM. Default: None"
    echo "  --add-workload [path]       Update the workload on the disk before deploying. Default: ./workload"
    echo "  --attach-disk               The data disk name, if the disk with the provided name is not provided, it will be created by the script"
    echo "  --disk-size                 The data disk size. Default: 10 GB"
    echo "  --create-ip <name>          Auto-create a static IP with this name (idempotent). Default: None"
    echo ""
    echo "Optional arguments for 'deploy-aws' command:"
    echo "  --bucket <name>             The name of an AWS bucket to store the vm image to. Default: randomly generated"
    echo "  --additional_ports <ports>  Comma-separated list of additional ports to open (e.g., \"80,443\"). Default: None"
    echo "  --vm_name <name>            The name of the virtual machine. Default: cvm-test"
    echo "  --region <region>           The region where the VM will be deployed. Default: \"us-east-2\""
    echo "  --vm_type <type>            The type of VM to be deployed. Default: \"m6a.large\""
    echo "  --eip <alloc_id>            The allocation ID of an Elastic IP to attach to the VM. Default: None"
    echo "  --add-workload [path]       Update the workload on the disk before deploying. Default: ./workload"
    echo "  --attach-disk                The data disk name, if the disk with the provided name is not provided, it will be created by the script"
    echo "  --disk-size                 The data disk size. Default: 10 GB"
    echo "  --create-ip <name>          Auto-create an Elastic IP with this name (idempotent). Default: None"
    echo ""
    echo "Arguments for the 'get-disk' command:"
    echo "  <CSP>          The cloud service provider (aws, gcp, azure)"
    echo ""
    echo "Arguments for 'verify-build-provenance' command:"
    echo "  <DISK_FILE>    Path to disk image (e.g., aws_disk.vmdk, azure_disk.vhd, gcp_disk.tar.gz)"
    echo "  [BUNDLE_FILE]  Optional: Path to build provenance bundle (defaults to <DISK_FILE>.bundle)"
    echo ""
    echo "Arguments for the 'update-disk' command:"
    echo "  <DISK_PATH>              The path to your disk image."
    echo "  <WORKLOAD_PATH>          Path to the workload directory to copy into the disk."
    echo ""
    echo "Arguments for the 'update-workload/get-logs/cleanup' command:"
    echo "  <CSP>          The cloud service provider (aws, gcp, azure)"
    echo "  <VM_NAME>      The name of the virtual machine to update"
    echo ""
    echo "Arguments for 'sign-image' command:"
    echo "  <source-image>           Source image (e.g., alpine:latest)"
    echo "  <target-image>           Target image (e.g., docker.io/user/image:signed)"
    echo "  <cosign-private>         Cosign private key"
    echo "  <cosign-public>          Cosign public key"
    echo ""
    echo "Arguments for 'sign-livepatch' command:"
    echo "  <livepatch-file>     The path to the livepatch file (e.g., /path/to/livepatch.ko)"
    echo ""
    echo "Arguments for 'livepatch' command:"
    echo "  <CSP>                The cloud provider (aws, gcp, azure)"
    echo "  <VM_NAME>            The name of the virtual machine"
    echo "  <PATH_TO_LIVEPATCH>  The path to the livepatch file (e.g., /path/to/livepatch.ko)"
    echo ""
    echo "Arguments for 'maintenance' command:"
    echo "  <CSP>                The cloud provider (aws, gcp, azure)"
    echo "  <VM_NAME>            The name of the virtual machine"
    echo "  <ACTION>             'enable' or 'disable'"
    echo "  [DELAY_SECONDS]      Optional delay in seconds before action takes effect (default: 0)"
    echo ""
    exit 1
}

COMMAND=$1
shift 1  # Shift to process other arguments

if [[ -z "$COMMAND" ]]; then
    usage
fi

case "$COMMAND" in
    deploy-aws)
        VM_NAME="cvm-test"
        BUCKET=""
        REGION="us-east-2"
        VM_TYPE="m6a.large"
        ADDITIONAL_PORTS=""
        EIP_AID=""
        ATTACH_DISK=""
        DISK_SIZE=""
        CREATE_IP_NAME=""

        while [[ "$#" -gt 0 ]]; do
            case "$1" in
                --additional_ports) ADDITIONAL_PORTS=$2; shift 2 ;;
                --vm_name) VM_NAME=$2; shift 2 ;;
                --region) REGION=$2; shift 2 ;;
                --vm_type) VM_TYPE=$2; shift 2 ;;
                --bucket) BUCKET=$2; shift 2 ;;
                --eip) EIP_AID=$2; shift 2 ;;
                --attach-disk) ATTACH_DISK=$2; shift 2 ;;
                --disk-size) DISK_SIZE=$2; shift 2 ;;
                --create-ip) CREATE_IP_NAME=$2; shift 2 ;;
                --add-workload)
                    # If next arg is another flag or missing, use default ./workload
                    if [[ -z "${2:-}" || "${2:0:2}" == "--" ]]; then
                        WORKLOAD_DIR="./workload"
                        shift 1
                    else
                        WORKLOAD_DIR="$2"
                        shift 2
                    fi
                    # Validate workload directory exists
                    if [[ ! -d "$WORKLOAD_DIR" ]]; then
                        echo "‚ùå Workload directory not found: $WORKLOAD_DIR"
                        exit 1
                    fi
                    ;;
                *) echo "Unknown argument: $1"; usage ;;
            esac
        done

        # Convert WORKLOAD_DIR to absolute path if it's relative
        if [[ -n "$WORKLOAD_DIR" && "${WORKLOAD_DIR:0:1}" != "/" ]]; then
            WORKLOAD_DIR="$(cd "$(dirname "$WORKLOAD_DIR")" && pwd)/$(basename "$WORKLOAD_DIR")"
        fi
        # Re-export WORKLOAD_DIR so child scripts see the updated value
        export WORKLOAD_DIR

        # === Derive bucket name if not provided ===
        if [[ -z "$BUCKET" ]]; then
            # Check whether bucket exists in _artifacts, use that first, if not generate a new one
            if [[ -f "$ARTIFACT_DIR/aws_${VM_NAME}_bucket" ]]; then
                BUCKET=$(<"$ARTIFACT_DIR/aws_${VM_NAME}_bucket")
                echo "‚ÑπÔ∏è  Using existing bucket name from artifacts: $BUCKET"
            else
                # Generate a new bucket name
                SANITIZED_VM_NAME=$(echo "$VM_NAME" | tr '[:upper:]' '[:lower:]' | tr -cd 'a-z0-9')
                RANDOM_SUFFIX=$(openssl rand -base64 32 | tr -dc 'a-z0-9' | head -c6)
                BUCKET="${SANITIZED_VM_NAME:-cvm}${RANDOM_SUFFIX}"
                echo "‚ÑπÔ∏è  No bucket provided. Using generated bucket name: $BUCKET"
            fi
        fi

        # === Auto-create Elastic IP if requested ===
        if [[ -n "$CREATE_IP_NAME" ]]; then
            echo "üîß Creating/reusing Elastic IP '$CREATE_IP_NAME'..."
            EIP_AID=$("$SCRIPT_DIR/create_static_ip_aws.sh" "$CREATE_IP_NAME" "$REGION" "$VM_NAME" "$ARTIFACT_DIR" | tail -1)
            echo "‚ÑπÔ∏è  Using Elastic IP allocation: $EIP_AID"
        fi

        set -euo pipefail
        # Check vm options
        "$SCRIPT_DIR/check_options.sh" "aws" "$VM_TYPE" "$REGION"
        # Change to disk directory for disk operations
        cd "$DISK_DIR"
        # Ensure the disk image exists
        "$SCRIPT_DIR/get_disk_image.sh" "aws"
        # Update the disk image with the latest workload
        if [[ -n "$WORKLOAD_DIR" ]]; then
            if [[ ! -d "$WORKLOAD_DIR" ]]; then
                echo "‚ùå Workload directory not found: $WORKLOAD_DIR"
                exit 1
            fi
            echo "üìÅ Adding workload from: $WORKLOAD_DIR"
            "$SCRIPT_DIR/update_disk.sh" "aws_disk.vmdk"
        fi
        # Check that CSP CLI dependencies are installed
        "$SCRIPT_DIR/check_csp_deps.sh" "aws"
        # Generate API token for disk
        "$SCRIPT_DIR/generate_api_token.sh" "aws_disk.vmdk" "aws" "$VM_NAME"
        # Deploy the VM
        echo "Deploying aws_disk.vmdk with the following parameters:"
        echo "üîπVM Name: $VM_NAME"
        echo "üîπRegion: $REGION"
        echo "üîπVM Type: $VM_TYPE"
        echo "üîπBucket : $BUCKET"
        echo "üîπEIP Allocation ID: $EIP_AID"
        echo "üîπAdditional Ports: $ADDITIONAL_PORTS"
        echo "üîπAttach Disk: ${ATTACH_DISK:-none}"
        echo "üîπDisk Size: ${DISK_SIZE:-default}"
        "$SCRIPT_DIR/make_aws_vm.sh" "$VM_NAME" "$REGION" "$VM_TYPE" "$BUCKET" "$ADDITIONAL_PORTS" "$EIP_AID" "$ATTACH_DISK" "$DISK_SIZE" "$ARTIFACT_DIR"
        "$SCRIPT_DIR/get_golden_measurements.sh" "aws" "$VM_NAME"
        echo "‚ú® Deployment complete! Your VM Name: $VM_NAME"
        set +e
        ;;

    deploy-gcp)
        # Default values
        PROJECT_ID=""
        BUCKET=""
        VM_NAME="cvm-test"
        REGION="asia-southeast1-b"
        VM_TYPE="c3-standard-4"
        # To specify additional workload ports, pass them as a comma-separated string
        # eg. "80,443"
        ADDITIONAL_PORTS=""
        IP=""
        ATTACH_DISK=""
        DISK_SIZE=""
        CREATE_IP_NAME=""

        while [[ "$#" -gt 0 ]]; do
            case "$1" in
                --additional_ports) ADDITIONAL_PORTS=$2; shift 2 ;;
                --vm_name) VM_NAME=$2; shift 2 ;;
                --region) REGION=$2; shift 2 ;;
                --project_id) PROJECT_ID=$2; shift 2 ;;
                --vm_type) VM_TYPE=$2; shift 2 ;;
                --bucket) BUCKET=$2; shift 2 ;;
                --ip) IP=$2; shift 2 ;;
                --attach-disk) ATTACH_DISK=$2; shift 2 ;;
                --disk-size) DISK_SIZE=$2; shift 2 ;;
                --create-ip) CREATE_IP_NAME=$2; shift 2 ;;
                --add-workload)
                    # If next arg is another flag or missing, use default ./workload
                    if [[ -z "${2:-}" || "${2:0:2}" == "--" ]]; then
                        WORKLOAD_DIR="./workload"
                        shift 1
                    else
                        WORKLOAD_DIR="$2"
                        shift 2
                    fi
                    # Validate workload directory exists
                    if [[ ! -d "$WORKLOAD_DIR" ]]; then
                        echo "‚ùå Workload directory not found: $WORKLOAD_DIR"
                        exit 1
                    fi
                    ;;
                *) echo "Unknown argument: $1"; usage ;;
            esac
        done

        # Convert WORKLOAD_DIR to absolute path if it's relative
        if [[ -n "$WORKLOAD_DIR" && "${WORKLOAD_DIR:0:1}" != "/" ]]; then
            WORKLOAD_DIR="$(cd "$(dirname "$WORKLOAD_DIR")" && pwd)/$(basename "$WORKLOAD_DIR")"
        fi
        # Re-export WORKLOAD_DIR so child scripts see the updated value
        export WORKLOAD_DIR

        # === Derive bucket name if not provided ===
        if [[ -z "$BUCKET" ]]; then
            # Check whether bucket exists in _artifacts, use that first, if not generate a new one
            if [[ -f "$ARTIFACT_DIR/gcp_${VM_NAME}_bucket" ]]; then
                BUCKET=$(<"$ARTIFACT_DIR/gcp_${VM_NAME}_bucket")
                echo "‚ÑπÔ∏è  Using existing bucket name from artifacts: $BUCKET"
            else
                # Generate a new bucket name
                SANITIZED_VM_NAME=$(echo "$VM_NAME" | tr '[:upper:]' '[:lower:]' | tr -cd 'a-z0-9')
                RANDOM_SUFFIX=$(openssl rand -base64 32 | tr -dc 'a-z0-9' | head -c6)
                BUCKET="${SANITIZED_VM_NAME:-cvm}${RANDOM_SUFFIX}"
                echo "‚ÑπÔ∏è  No bucket provided. Using generated bucket name: $BUCKET"
            fi
        fi

        set -euo pipefail
        # Check vm options
        "$SCRIPT_DIR/check_options.sh" "gcp" "$VM_TYPE" "$REGION"
        # Change to disk directory for disk operations
        cd "$DISK_DIR"
        # Ensure the disk image exists
        "$SCRIPT_DIR/get_disk_image.sh" "gcp"
        # Update the disk image with the latest workload
        if [[ -n "$WORKLOAD_DIR" ]]; then
            if [[ ! -d "$WORKLOAD_DIR" ]]; then
                echo "‚ùå Workload directory not found: $WORKLOAD_DIR"
                exit 1
            fi
            echo "üìÅ Adding workload from: $WORKLOAD_DIR"
            "$SCRIPT_DIR/update_disk.sh" "gcp_disk.tar.gz"
        fi
        # Check that CSP CLI dependencies are installed
        "$SCRIPT_DIR/check_csp_deps.sh" "gcp"

        # === Derive PROJECT_ID if not provided ===
        if [[ -z "$PROJECT_ID" ]]; then
            PROJECT_ID=$(gcloud config get-value project 2>/dev/null)
            if [[ -z "$PROJECT_ID" ]]; then
                echo "‚ùå PROJECT_ID not provided and no default found in gcloud config."
                echo "‚ùå To fix run this command: gcloud init --console-only --no-launch-browser"
                exit 1
            fi
            echo "‚ÑπÔ∏è  Using default gcloud project: $PROJECT_ID"
        fi

        # === Auto-create static IP if requested ===
        if [[ -n "$CREATE_IP_NAME" ]]; then
            echo "üîß Creating/reusing static IP '$CREATE_IP_NAME'..."
            IP=$("$SCRIPT_DIR/create_static_ip_gcp.sh" "$CREATE_IP_NAME" "$REGION" "$PROJECT_ID" "$VM_NAME" "$ARTIFACT_DIR" | tail -1)
            echo "‚ÑπÔ∏è  Using static IP: $IP"
        fi

        # Generate API token for disk
        "$SCRIPT_DIR/generate_api_token.sh" "gcp_disk.tar.gz" "gcp" "$VM_NAME"
        # Deploy the VM
        echo "Deploying gcp_disk.tar.gz with the following parameters:"
        echo "üîπVM Name: $VM_NAME"
        echo "üîπRegion: $REGION"
        echo "üîπProject ID: $PROJECT_ID"
        echo "üîπVM Type: $VM_TYPE"
        echo "üîπBucket : $BUCKET"
        echo "üîπAdditional Ports: $ADDITIONAL_PORTS"
        echo "üîπAttach Disk: ${ATTACH_DISK:-none}"
        echo "üîπDisk Size: ${DISK_SIZE:-default}"
        "$SCRIPT_DIR/make_gcp_vm.sh" "$VM_NAME" "$REGION" "$PROJECT_ID" "$VM_TYPE" "$BUCKET" "$ADDITIONAL_PORTS" "$IP" "$ATTACH_DISK" "$DISK_SIZE" "$ARTIFACT_DIR"
        "$SCRIPT_DIR/get_golden_measurements.sh" "gcp" "$VM_NAME"
        echo "‚ú® Deployment complete! Your VM Name: $VM_NAME"
        set +e
        ;;

 deploy-azure)
        # Default values
        VM_NAME="cvm-test"
        VM_TYPE="Standard_DC2es_v6"
        REGION="East US"
        RESOURCE_GROUP=""
        STORAGE_ACC=""
        GALLERY_NAME=""
        ADDITIONAL_PORTS=""
        ATTACH_DISK=""
        DISK_SIZE=""
        CREATE_IP_NAME=""

        while [[ "$#" -gt 0 ]]; do
            case "$1" in
                --additional_ports) ADDITIONAL_PORTS=$2; shift 2 ;;
                --vm_name) VM_NAME=$2; shift 2 ;;
                --vm_type) VM_TYPE=$2; shift 2 ;;
                --region) REGION=$2; shift 2 ;;
                --resource_group) RESOURCE_GROUP=$2; shift 2;;
                --storage_account) STORAGE_ACC=$2; shift 2 ;;
                --gallery_name) GALLERY_NAME=$2; shift 2 ;;
                --create-ip) CREATE_IP_NAME=$2; shift 2 ;;
                --add-workload)
                    # If next arg is another flag or missing, use default ./workload
                    if [[ -z "${2:-}" || "${2:0:2}" == "--" ]]; then
                        WORKLOAD_DIR="./workload"
                        shift 1
                    else
                        WORKLOAD_DIR="$2"
                        shift 2
                    fi
                    # Validate workload directory exists
                    if [[ ! -d "$WORKLOAD_DIR" ]]; then
                        echo "‚ùå Workload directory not found: $WORKLOAD_DIR"
                        exit 1
                    fi
                    ;;
                --attach-disk) ATTACH_DISK=$2; shift 2 ;;
                --disk-size) DISK_SIZE=$2; shift 2 ;;
                *) echo "Unknown argument: $1"; usage ;;
            esac
        done

        # Convert WORKLOAD_DIR to absolute path if it's relative
        if [[ -n "$WORKLOAD_DIR" && "${WORKLOAD_DIR:0:1}" != "/" ]]; then
            WORKLOAD_DIR="$(cd "$(dirname "$WORKLOAD_DIR")" && pwd)/$(basename "$WORKLOAD_DIR")"
        fi
        # Re-export WORKLOAD_DIR so child scripts see the updated value
        export WORKLOAD_DIR

        set -euo pipefail
        # Check that CSP CLI dependencies are installed
        "$SCRIPT_DIR/check_csp_deps.sh" "azure"

        # === Derive from VM_NAME ===
        if [[ -z "$RESOURCE_GROUP" ]]; then
          RESOURCE_GROUP="${VM_NAME}_Rg"
        fi

        RANDOM_SUFFIX=$(openssl rand -base64 32 | tr -dc 'a-z0-9' | head -c4)
        if [[ -z "$STORAGE_ACC" ]]; then
            # Get the name of the first storage account (if any)
            STORAGE_ACC=$(az storage account list --resource-group "$RESOURCE_GROUP" --query "[0].name" --output tsv 2>/dev/null || true)
            if [[ -n "$STORAGE_ACC" ]]; then
                echo "Found storage account: $STORAGE_ACC"
            else
                STORAGE_ACC=$(echo "$VM_NAME" | tr '[:upper:]' '[:lower:]' | tr -cd 'a-z0-9' | cut -c1-20)
                STORAGE_ACC="${STORAGE_ACC}${RANDOM_SUFFIX}"
                while [[ ${#STORAGE_ACC} -lt 3 ]]; do
                    STORAGE_ACC="${STORAGE_ACC}0"
                done
            fi
        fi
        if [[ -z "$GALLERY_NAME" ]]; then
            # Get the name of the first Shared Image Gallery (if any)
            GALLERY_NAME=$(az sig list --resource-group "$RESOURCE_GROUP" --query "[0].name" --output tsv 2>/dev/null || true)
            if [[ -n "$GALLERY_NAME" ]]; then
                echo "Found shared image gallery: $GALLERY_NAME"
            else
                GALLERY_NAME=$(echo "$VM_NAME" | tr '[:upper:]' '[:lower:]' | tr -cd 'a-z0-9_.' | sed 's/^[_.]*//;s/[_.]*$//' | cut -c1-80)
                GALLERY_NAME="${GALLERY_NAME}${RANDOM_SUFFIX}"
            fi
        fi
        # In case the resource group exists, ensure the region matches
        LOCATION=$(az group show --name "$RESOURCE_GROUP" --query "location" --output tsv 2>/dev/null || true)
        if [[ -n "$LOCATION" ]]; then
            FRIENDLY_LOCATION=$(az account list-locations --query "[?name=='$LOCATION'].displayName" --output tsv)
            if [[ "$FRIENDLY_LOCATION" != "$REGION" ]]; then
                echo "Resource group is in $FRIENDLY_LOCATION. Updating REGION to match."
                REGION="$FRIENDLY_LOCATION"
            fi
        fi

        # === Auto-create static IP if requested ===
        STATIC_IP_NAME=""
        if [[ -n "$CREATE_IP_NAME" ]]; then
            echo "üîß Creating/reusing static IP '$CREATE_IP_NAME'..."
            STATIC_IP_NAME=$("$SCRIPT_DIR/create_static_ip_azure.sh" "$CREATE_IP_NAME" "$RESOURCE_GROUP" "$REGION" "$VM_NAME" "$ARTIFACT_DIR" | tail -1)
            echo "‚ÑπÔ∏è  Using static IP resource: $STATIC_IP_NAME"
        fi

        # Check vm options
        "$SCRIPT_DIR/check_options.sh" "azure" "$VM_TYPE" "$REGION"
        # Change to disk directory for disk operations
        cd "$DISK_DIR"
        # Ensure the disk image exists
        "$SCRIPT_DIR/get_disk_image.sh" "azure"
        # Update the disk image with the latest workload
        if [[ -n "$WORKLOAD_DIR" ]]; then
            if [[ ! -d "$WORKLOAD_DIR" ]]; then
                echo "‚ùå Workload directory not found: $WORKLOAD_DIR"
                exit 1
            fi
            echo "üìÅ Adding workload from: $WORKLOAD_DIR"
            "$SCRIPT_DIR/update_disk.sh" "azure_disk.vhd"
        fi
        # Generate API token for disk
        "$SCRIPT_DIR/generate_api_token.sh" "azure_disk.vhd" "azure" "$VM_NAME"
        echo "Deploying azure_disk.vhd with the following parameters:"
        echo "üîπVM Name: $VM_NAME"
        echo "üîπResource Group: $RESOURCE_GROUP"
        echo "üîπRegion: $REGION"
        echo "üîπVM Type: $VM_TYPE"
        echo "üîπAdditional Ports: $ADDITIONAL_PORTS"
        echo "üîπStorage Account: $STORAGE_ACC"
        echo "üîπShared Image Gallery: $GALLERY_NAME"
        echo "üîπAttach Disk: ${ATTACH_DISK:-none}"
        echo "üîπDisk Size: ${DISK_SIZE:-default}"

        "$SCRIPT_DIR/make_azure_vm.sh" "$VM_NAME" "$RESOURCE_GROUP" "$VM_TYPE" "$ADDITIONAL_PORTS"  \
                        "$STORAGE_ACC" "$GALLERY_NAME" "$REGION" "$ATTACH_DISK" "$DISK_SIZE" "$ARTIFACT_DIR" "$STATIC_IP_NAME"
        "$SCRIPT_DIR/get_golden_measurements.sh" "azure" "$VM_NAME"
        echo "‚ú® Deployment complete! Your VM Name: $VM_NAME"
        set +e
        ;;

    update-workload)
        CSP=$1; shift 1
        VM_NAME=$1; shift 1
        if [[ -z "$CSP" || -z "$VM_NAME" ]]; then
            echo "‚ùå Please provide the CSP (aws, gcp or azure) and VM name."
            echo "‚ùå Usage: $0 update-workload <CSP> <VM_NAME>"
            exit 1
        fi
        set -euo pipefail
        "$SCRIPT_DIR/update_remote_workload.sh" "$CSP" "$VM_NAME"
        echo "Updating golden measurements..."
        "$SCRIPT_DIR/get_golden_measurements.sh" "$CSP" "$VM_NAME"
        set +e
        ;;

    get-disk)
        CSP=$1; shift 1
        if [[ -z "$CSP" ]]; then
            echo "‚ùå Please provide the CSP (aws, gcp or azure)."
            echo "‚ùå Usage: $0 get-disk <CSP>"
            exit 1
        fi
        cd "$DISK_DIR"
        "$SCRIPT_DIR/get_disk_image.sh" "$CSP"
        ;;

    download-build-provenance)
        echo "üì¶ Downloading SLSA build provenance..."
        cd "$DISK_DIR"
        "$SCRIPT_DIR/get_build_provenance.sh"
        ;;

    verify-build-provenance)
        DISK_FILE=$1; shift 1
        BUNDLE_FILE="${1:-}"
        if [[ -z "$DISK_FILE" ]]; then
            echo "‚ùå Please provide the disk file to verify"
            echo "‚ùå Usage: $0 verify-build-provenance <DISK_FILE> [BUNDLE_FILE]"
            exit 1
        fi
        if [[ -n "$BUNDLE_FILE" ]]; then
            "$SCRIPT_DIR/verify_build_provenance.sh" "$DISK_FILE" "$BUNDLE_FILE"
        else
            "$SCRIPT_DIR/verify_build_provenance.sh" "$DISK_FILE"
        fi
        ;;

    update-disk)
        DISK_FILE="${1:-}"; shift 1 || true
        WORKLOAD_PATH="${1:-}"; shift 1 || true
        if [[ -z "$DISK_FILE" || -z "$WORKLOAD_PATH" ]]; then
            echo "‚ùå Please provide both the disk file and workload path."
            echo "‚ùå Usage: $0 update-disk <DISK_PATH> <WORKLOAD_PATH>"
            exit 1
        fi
        if [[ ! -d "$WORKLOAD_PATH" ]]; then
            echo "‚ùå Workload directory not found: $WORKLOAD_PATH"
            exit 1
        fi
        export WORKLOAD_DIR="$WORKLOAD_PATH"
        echo "üìÄ Updating disk: $DISK_FILE"
        echo "üìÅ Workload source: $WORKLOAD_PATH"
        cd "$DISK_DIR"
        "$SCRIPT_DIR/update_disk.sh" "$DISK_FILE"
        ;;

    get-logs)
        CSP=$1; shift 1
        VM_NAME=$1; shift 1
        if [[ -z "$CSP" || -z "$VM_NAME" ]]; then
            echo "‚ùå Please provide the CSP (aws, gcp or azure) and VM name."
            echo "‚ùå Usage: $0 get-logs <CSP> <VM_NAME>"
            exit 1
        fi
        set -euo pipefail
        "$SCRIPT_DIR/get_cvm_logs.sh" "$CSP" "$VM_NAME"
        set +e
        ;;

    cleanup)
        CSP=$1; shift 1
        VM_NAME=$1; shift 1
        if [[ -z "$CSP" || -z "$VM_NAME" ]]; then
            echo "‚ùå Please provide the CSP (aws, gcp or azure) and VM name."
            echo "‚ùå Usage: $0 cleanup <CSP> <VM_NAME>"
            exit 1
        fi
        case "$CSP" in
            aws)
                "$SCRIPT_DIR/cleanup_aws_vm.sh" "$VM_NAME" "$ARTIFACT_DIR"
                ;;
            gcp)
                "$SCRIPT_DIR/cleanup_gcp_vm.sh" "$VM_NAME" "$ARTIFACT_DIR"
                ;;
            azure)
                "$SCRIPT_DIR/cleanup_azure_vm.sh" "$VM_NAME" "$ARTIFACT_DIR"
                ;;
        esac
        ;;

    cleanup-local)
        echo "üßπ Cleaning up local artifacts..."

        # Clean disk images
        DISK_FILES=("aws_disk.vmdk" "gcp_disk.tar.gz" "azure_disk.vhd")
        for disk in "${DISK_FILES[@]}"; do
            if [[ -f "$DISK_DIR/$disk" ]]; then
                rm -f "$DISK_DIR/$disk"
                echo "  Removed: $DISK_DIR/$disk"
            fi
        done

        # Clean build provenance bundles
        for disk in "${DISK_FILES[@]}"; do
            if [[ -f "$DISK_DIR/${disk}.bundle" ]]; then
                rm -f "$DISK_DIR/${disk}.bundle"
                echo "  Removed: $DISK_DIR/${disk}.bundle"
            fi
        done

        # Clean artifacts directory
        if [[ -d "$ARTIFACT_DIR" ]]; then
            rm -rf "$ARTIFACT_DIR"/*
            echo "  Cleaned: $ARTIFACT_DIR"
        fi

        echo "‚úÖ Local cleanup complete!"
        ;;

    sign-livepatch)
        LIVEPATCH_FILE=$1; shift 1
        if [[ -z "$LIVEPATCH_FILE" ]]; then
            echo "‚ùå Please provide the livepatch file (e.g., /path/to/livepatch.ko)"
            echo "‚ùå Usage: $0 sign-livepatch <LIVEPATCH_FILE>"
            exit 1
        fi
        set -euo pipefail
        "$SCRIPT_DIR/sign_livepatch.sh" "$LIVEPATCH_FILE"
        echo "Livepatch signed successfully: $LIVEPATCH_FILE"
        set +e
        ;;

    livepatch)
        CSP=$1; shift 1
        VM_NAME=$1; shift 1
        LIVEPATCH_PATH=$1; shift 1
        if [[ -z "$CSP" || -z "$VM_NAME" || -z "$LIVEPATCH_PATH" ]]; then
            echo "‚ùå Please provide the CSP (aws, gcp or azure), VM name, and path to the livepatch file."
            echo "‚ùå Usage: $0 livepatch <CSP> <VM_NAME> <PATH_TO_LIVEPATCH>"
            exit 1
        fi
        set -euo pipefail
        "$SCRIPT_DIR/livepatch.sh" "$CSP" "$VM_NAME" "$LIVEPATCH_PATH"
        set +e
        ;;

    generate-livepatch-keys)
        # Generate livepatch keys
        "$SCRIPT_DIR/generate_livepatch_keys.sh"
        ;;

    sign-image)
        SOURCE_IMAGE="$1"
        TARGET_IMAGE="$2"
        COSIGN_PRI="$3"
        COSIGN_PUB="$4"

        if [[ -z "$SOURCE_IMAGE" || -z "$TARGET_IMAGE" || -z "$COSIGN_PRI" || -z "$COSIGN_PUB" ]]; then
            echo "‚ùå Usage: $0 sign-image <source-image> <target-image> <cosign.key> <cosign.pub>"
            echo "Example: $0 sign-image alpine:latest docker.io/user/alpine:signed cosign.key cosign.pub"
            exit 1
        fi
        "$SCRIPT_DIR/sign-and-verify.sh" "$SOURCE_IMAGE" "$TARGET_IMAGE" "$COSIGN_PRI" "$COSIGN_PUB"
        ;;

    maintenance)
        CSP=$1; shift 1
        VM_NAME=$1; shift 1
        ACTION=$1; shift 1
        DELAY="${1:-0}"; shift 1 2>/dev/null || true
        if [[ -z "$CSP" || -z "$VM_NAME" || -z "$ACTION" ]]; then
            echo "‚ùå Please provide CSP, VM name, and action (enable/disable)."
            echo "‚ùå Usage: $0 maintenance <CSP> <VM_NAME> <enable|disable> [DELAY_SECONDS]"
            exit 1
        fi
        set -euo pipefail
        "$SCRIPT_DIR/maintenance_mode.sh" "$CSP" "$VM_NAME" "$ACTION" "$DELAY"
        set +e
        ;;

    *)
        echo "Unknown command: $COMMAND"
        usage
        ;;
esac

exit 0
